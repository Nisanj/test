{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1.]\n",
      "     Actual  Predicted\n",
      "225     0.0        0.0\n",
      "152     1.0        1.0\n",
      "228     0.0        1.0\n",
      "201     0.0        0.0\n",
      "52      1.0        0.0\n",
      "245     0.0        1.0\n",
      "175     0.0        0.0\n",
      "168     0.0        0.0\n",
      "223     0.0        0.0\n",
      "217     0.0        0.0\n",
      "111     1.0        1.0\n",
      "135     1.0        1.0\n",
      "218     0.0        0.0\n",
      "12      1.0        1.0\n",
      "15      1.0        1.0\n",
      "66      1.0        1.0\n",
      "97      1.0        0.0\n",
      "90      1.0        1.0\n",
      "198     0.0        0.0\n",
      "103     1.0        1.0\n",
      "22      1.0        1.0\n",
      "212     0.0        0.0\n",
      "226     0.0        0.0\n",
      "264     0.0        0.0\n",
      "133     1.0        1.0\n",
      "216     0.0        0.0\n",
      "275     0.0        0.0\n",
      "270     0.0        0.0\n",
      "154     1.0        1.0\n",
      "55      1.0        1.0\n",
      "194     0.0        1.0\n",
      "[[14  3]\n",
      " [ 2 12]]\n",
      "Accuracy: 83.87%\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = pd.read_csv(\"heart.csv\")\n",
    "data.head()\n",
    "#data.dtypes\n",
    "#data.dtypes\n",
    "for x in data:\n",
    "    if data[x].dtypes == \"int64\":\n",
    "        data[x] = data[x].astype(float)\n",
    "        #print (data[x].dtypes)\n",
    "#data.dtypes\n",
    "X = data.drop('target',axis=1)\n",
    "y = data['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "print(df)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "row = [57,0,0,120,354,0,1,163,1,0.6,2,0,2]\n",
    "row = asarray([row])\n",
    "yhat = classifier.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nisarga/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:54:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 70.97%\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "row = [57,0,0,120,354,0,1,163,1,0.6,2,0,2]\n",
    "row = asarray([row])\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
